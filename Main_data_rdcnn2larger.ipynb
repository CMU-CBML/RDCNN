{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Improved balance data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading datasets\n",
      "===> Building model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import data\n",
    "from dataset import rdDataset_old\n",
    "from dataset import H5Dataset\n",
    "from model import rdcnn_2_larger\n",
    "from model import rdcnn_unet\n",
    "from math import log10\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "path = './data'\n",
    "\n",
    "# Parameters\n",
    "\n",
    "params = {'test_split': .25,\n",
    "          'shuffle_dataset': True,\n",
    "          'batchsize': 32,\n",
    "          'testBatchsize': 32,\n",
    "          'random_seed': 42,\n",
    "          'numworkers':32,\n",
    "          'pinmemory':True}\n",
    "max_epoches = 100\n",
    "learning_rate = 1e-3\n",
    "drop_rate = 0.0\n",
    "\n",
    "print('===> Loading datasets')\n",
    "# Load All Dataset\n",
    "# dataset = rdDataset_old(path)\n",
    "\n",
    "# Test new dataset format\n",
    "dataset = H5Dataset('data_all.hdf5')\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "training_data_loader, testing_data_loader = data.DatasetSplit(dataset, **params)\n",
    "\n",
    "print('===> Building model')\n",
    "model = rdcnn_2_larger(drop_rate).to(device)\n",
    "# model = rdcnn_unet(drop_rate).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = batch[0].to(device, torch.float), batch[1].to(device, torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(input), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "    return epoch, epoch_loss / len(training_data_loader)\n",
    "    \n",
    "def test():\n",
    "    avg_error = 0\n",
    "    avg_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in testing_data_loader:\n",
    "            input, target = batch[0].to(device, torch.float), batch[1].to(device, torch.float)\n",
    "\n",
    "            prediction = model(input)\n",
    "            tmp_error = 0\n",
    "#             print(len(prediction))\n",
    "            for j in range(len(prediction)):\n",
    "#                 tmp_error += torch.mean((prediction[j]-target[j])**2/torch.max(target[j]))\n",
    "                tmp_error += torch.sqrt(torch.mean((prediction[j]-target[j])**2))/torch.max(target[j])\n",
    "            avg_error += tmp_error / len(prediction)\n",
    "            mse = criterion(prediction, target)\n",
    "            avg_loss += mse\n",
    "    print(\"===> Avg. Loss: {:.4f} \".format(avg_loss / len(testing_data_loader)))\n",
    "    print(\"===> Avg. Error: {:.4f} \".format(avg_error / len(testing_data_loader)))\n",
    "    return avg_loss / len(testing_data_loader),avg_error / len(testing_data_loader)\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    model_out_path = \"./checkpoint_databc1_larger_h5/model_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(model, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 1 Complete: Avg. Loss: 0.1173\n",
      "===> Avg. Loss: 0.0341 \n",
      "===> Avg. Error: 0.0490 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_1.pth\n",
      "===> Epoch 2 Complete: Avg. Loss: 0.0158\n",
      "===> Avg. Loss: 0.0230 \n",
      "===> Avg. Error: 0.0483 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_2.pth\n",
      "===> Epoch 3 Complete: Avg. Loss: 0.0170\n",
      "===> Avg. Loss: 0.0296 \n",
      "===> Avg. Error: 0.0398 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_3.pth\n",
      "===> Epoch 4 Complete: Avg. Loss: 0.0172\n",
      "===> Avg. Loss: 0.0303 \n",
      "===> Avg. Error: 0.0385 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_4.pth\n",
      "===> Epoch 5 Complete: Avg. Loss: 0.0177\n",
      "===> Avg. Loss: 0.0235 \n",
      "===> Avg. Error: 0.0383 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_5.pth\n",
      "===> Epoch 6 Complete: Avg. Loss: 0.0175\n",
      "===> Avg. Loss: 0.0283 \n",
      "===> Avg. Error: 0.0378 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_6.pth\n",
      "===> Epoch 7 Complete: Avg. Loss: 0.0191\n",
      "===> Avg. Loss: 0.0286 \n",
      "===> Avg. Error: 0.0364 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_7.pth\n",
      "===> Epoch 8 Complete: Avg. Loss: 0.0154\n",
      "===> Avg. Loss: 0.0263 \n",
      "===> Avg. Error: 0.0360 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_8.pth\n",
      "===> Epoch 9 Complete: Avg. Loss: 0.0141\n",
      "===> Avg. Loss: 0.0268 \n",
      "===> Avg. Error: 0.0356 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_9.pth\n",
      "===> Epoch 10 Complete: Avg. Loss: 0.0192\n",
      "===> Avg. Loss: 0.0302 \n",
      "===> Avg. Error: 0.0398 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_10.pth\n",
      "===> Epoch 11 Complete: Avg. Loss: 0.0142\n",
      "===> Avg. Loss: 0.0422 \n",
      "===> Avg. Error: 0.0375 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_11.pth\n",
      "===> Epoch 12 Complete: Avg. Loss: 0.0190\n",
      "===> Avg. Loss: 0.0326 \n",
      "===> Avg. Error: 0.0365 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_12.pth\n",
      "===> Epoch 13 Complete: Avg. Loss: 0.0172\n",
      "===> Avg. Loss: 0.0236 \n",
      "===> Avg. Error: 0.0462 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_13.pth\n",
      "===> Epoch 14 Complete: Avg. Loss: 0.0141\n",
      "===> Avg. Loss: 0.0198 \n",
      "===> Avg. Error: 0.0384 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_14.pth\n",
      "===> Epoch 15 Complete: Avg. Loss: 0.0141\n",
      "===> Avg. Loss: 0.0288 \n",
      "===> Avg. Error: 0.0367 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_15.pth\n",
      "===> Epoch 16 Complete: Avg. Loss: 0.0151\n",
      "===> Avg. Loss: 0.0251 \n",
      "===> Avg. Error: 0.0517 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_16.pth\n",
      "===> Epoch 17 Complete: Avg. Loss: 0.0172\n",
      "===> Avg. Loss: 0.0316 \n",
      "===> Avg. Error: 0.0338 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_17.pth\n",
      "===> Epoch 18 Complete: Avg. Loss: 0.0181\n",
      "===> Avg. Loss: 0.0388 \n",
      "===> Avg. Error: 0.0374 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_18.pth\n",
      "===> Epoch 19 Complete: Avg. Loss: 0.0169\n",
      "===> Avg. Loss: 0.0274 \n",
      "===> Avg. Error: 0.0340 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_19.pth\n",
      "===> Epoch 20 Complete: Avg. Loss: 0.0170\n",
      "===> Avg. Loss: 0.0286 \n",
      "===> Avg. Error: 0.0382 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_20.pth\n",
      "===> Epoch 21 Complete: Avg. Loss: 0.0198\n",
      "===> Avg. Loss: 0.0291 \n",
      "===> Avg. Error: 0.0391 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_21.pth\n",
      "===> Epoch 22 Complete: Avg. Loss: 0.0166\n",
      "===> Avg. Loss: 0.0211 \n",
      "===> Avg. Error: 0.0320 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_22.pth\n",
      "===> Epoch 23 Complete: Avg. Loss: 0.0167\n",
      "===> Avg. Loss: 0.0301 \n",
      "===> Avg. Error: 0.0376 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_23.pth\n",
      "===> Epoch 24 Complete: Avg. Loss: 0.0171\n",
      "===> Avg. Loss: 0.0371 \n",
      "===> Avg. Error: 0.0358 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_24.pth\n",
      "===> Epoch 25 Complete: Avg. Loss: 0.0194\n",
      "===> Avg. Loss: 0.0300 \n",
      "===> Avg. Error: 0.0354 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_25.pth\n",
      "===> Epoch 26 Complete: Avg. Loss: 0.0163\n",
      "===> Avg. Loss: 0.0230 \n",
      "===> Avg. Error: 0.0418 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_26.pth\n",
      "===> Epoch 27 Complete: Avg. Loss: 0.0139\n",
      "===> Avg. Loss: 0.0294 \n",
      "===> Avg. Error: 0.0353 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_27.pth\n",
      "===> Epoch 28 Complete: Avg. Loss: 0.0160\n",
      "===> Avg. Loss: 0.0290 \n",
      "===> Avg. Error: 0.0352 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_28.pth\n",
      "===> Epoch 29 Complete: Avg. Loss: 0.0152\n",
      "===> Avg. Loss: 0.0272 \n",
      "===> Avg. Error: 0.0399 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_29.pth\n",
      "===> Epoch 30 Complete: Avg. Loss: 0.0155\n",
      "===> Avg. Loss: 0.0197 \n",
      "===> Avg. Error: 0.0377 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_30.pth\n",
      "===> Epoch 31 Complete: Avg. Loss: 0.0141\n",
      "===> Avg. Loss: 0.0276 \n",
      "===> Avg. Error: inf \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_31.pth\n",
      "===> Epoch 32 Complete: Avg. Loss: 0.0185\n",
      "===> Avg. Loss: 0.0261 \n",
      "===> Avg. Error: 0.0431 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_32.pth\n",
      "===> Epoch 33 Complete: Avg. Loss: 0.0177\n",
      "===> Avg. Loss: 0.0222 \n",
      "===> Avg. Error: 0.0363 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_33.pth\n",
      "===> Epoch 34 Complete: Avg. Loss: 0.0173\n",
      "===> Avg. Loss: 0.0214 \n",
      "===> Avg. Error: 0.0331 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_34.pth\n",
      "===> Epoch 35 Complete: Avg. Loss: 0.0198\n",
      "===> Avg. Loss: 0.0266 \n",
      "===> Avg. Error: 0.0384 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_35.pth\n",
      "===> Epoch 36 Complete: Avg. Loss: 0.0127\n",
      "===> Avg. Loss: 0.0314 \n",
      "===> Avg. Error: 0.0396 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_36.pth\n",
      "===> Epoch 37 Complete: Avg. Loss: 0.0149\n",
      "===> Avg. Loss: 0.0199 \n",
      "===> Avg. Error: 0.0332 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_37.pth\n",
      "===> Epoch 38 Complete: Avg. Loss: 0.0147\n",
      "===> Avg. Loss: 0.0417 \n",
      "===> Avg. Error: 0.0356 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_38.pth\n",
      "===> Epoch 39 Complete: Avg. Loss: 0.0180\n",
      "===> Avg. Loss: 0.0403 \n",
      "===> Avg. Error: 0.0389 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_39.pth\n",
      "===> Epoch 40 Complete: Avg. Loss: 0.0150\n",
      "===> Avg. Loss: 0.0209 \n",
      "===> Avg. Error: inf \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_40.pth\n",
      "===> Epoch 41 Complete: Avg. Loss: 0.0135\n",
      "===> Avg. Loss: 0.0270 \n",
      "===> Avg. Error: 0.0343 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_41.pth\n",
      "===> Epoch 42 Complete: Avg. Loss: 0.0188\n",
      "===> Avg. Loss: 0.0340 \n",
      "===> Avg. Error: inf \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_42.pth\n",
      "===> Epoch 43 Complete: Avg. Loss: 0.0128\n",
      "===> Avg. Loss: 0.0308 \n",
      "===> Avg. Error: 0.0458 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_43.pth\n",
      "===> Epoch 44 Complete: Avg. Loss: 0.0167\n",
      "===> Avg. Loss: 0.0237 \n",
      "===> Avg. Error: 0.0342 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_44.pth\n",
      "===> Epoch 45 Complete: Avg. Loss: 0.0143\n",
      "===> Avg. Loss: 0.0268 \n",
      "===> Avg. Error: 0.0523 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_45.pth\n",
      "===> Epoch 46 Complete: Avg. Loss: 0.0188\n",
      "===> Avg. Loss: 0.0236 \n",
      "===> Avg. Error: 0.0363 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_46.pth\n",
      "===> Epoch 47 Complete: Avg. Loss: 0.0187\n",
      "===> Avg. Loss: 0.0332 \n",
      "===> Avg. Error: 0.0357 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_47.pth\n",
      "===> Epoch 48 Complete: Avg. Loss: 0.0188\n",
      "===> Avg. Loss: 0.0176 \n",
      "===> Avg. Error: 0.0420 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_48.pth\n",
      "===> Epoch 49 Complete: Avg. Loss: 0.0196\n",
      "===> Avg. Loss: 0.0179 \n",
      "===> Avg. Error: 0.0461 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_49.pth\n",
      "===> Epoch 50 Complete: Avg. Loss: 0.0140\n",
      "===> Avg. Loss: 0.0383 \n",
      "===> Avg. Error: 0.0385 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_50.pth\n",
      "===> Epoch 51 Complete: Avg. Loss: 0.0178\n",
      "===> Avg. Loss: 0.0412 \n",
      "===> Avg. Error: 0.0406 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_51.pth\n",
      "===> Epoch 52 Complete: Avg. Loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Avg. Loss: 0.0232 \n",
      "===> Avg. Error: 0.0333 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_52.pth\n",
      "===> Epoch 53 Complete: Avg. Loss: 0.0184\n",
      "===> Avg. Loss: 0.0206 \n",
      "===> Avg. Error: 0.0342 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_53.pth\n",
      "===> Epoch 54 Complete: Avg. Loss: 0.0170\n",
      "===> Avg. Loss: 0.0248 \n",
      "===> Avg. Error: 0.0342 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_54.pth\n",
      "===> Epoch 55 Complete: Avg. Loss: 0.0131\n",
      "===> Avg. Loss: 0.0310 \n",
      "===> Avg. Error: 0.0351 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_55.pth\n",
      "===> Epoch 56 Complete: Avg. Loss: 0.0151\n",
      "===> Avg. Loss: 0.0293 \n",
      "===> Avg. Error: 0.0382 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_56.pth\n",
      "===> Epoch 57 Complete: Avg. Loss: 0.0207\n",
      "===> Avg. Loss: 0.0265 \n",
      "===> Avg. Error: 0.0344 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_57.pth\n",
      "===> Epoch 58 Complete: Avg. Loss: 0.0179\n",
      "===> Avg. Loss: 0.0216 \n",
      "===> Avg. Error: 0.0312 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_58.pth\n",
      "===> Epoch 59 Complete: Avg. Loss: 0.0159\n",
      "===> Avg. Loss: 0.0226 \n",
      "===> Avg. Error: 0.0346 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_59.pth\n",
      "===> Epoch 60 Complete: Avg. Loss: 0.0178\n",
      "===> Avg. Loss: 0.0287 \n",
      "===> Avg. Error: inf \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_60.pth\n",
      "===> Epoch 61 Complete: Avg. Loss: 0.0188\n",
      "===> Avg. Loss: 0.0264 \n",
      "===> Avg. Error: 0.0392 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_61.pth\n",
      "===> Epoch 62 Complete: Avg. Loss: 0.0138\n",
      "===> Avg. Loss: 0.0307 \n",
      "===> Avg. Error: 0.0360 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_62.pth\n",
      "===> Epoch 63 Complete: Avg. Loss: 0.0174\n",
      "===> Avg. Loss: 0.0350 \n",
      "===> Avg. Error: 0.0372 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_63.pth\n",
      "===> Epoch 64 Complete: Avg. Loss: 0.0134\n",
      "===> Avg. Loss: 0.0241 \n",
      "===> Avg. Error: 0.0326 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_64.pth\n",
      "===> Epoch 65 Complete: Avg. Loss: 0.0177\n",
      "===> Avg. Loss: 0.0279 \n",
      "===> Avg. Error: 0.0454 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_65.pth\n",
      "===> Epoch 66 Complete: Avg. Loss: 0.0138\n",
      "===> Avg. Loss: 0.0295 \n",
      "===> Avg. Error: 0.0350 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_66.pth\n",
      "===> Epoch 67 Complete: Avg. Loss: 0.0149\n",
      "===> Avg. Loss: 0.0400 \n",
      "===> Avg. Error: 0.0369 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_67.pth\n",
      "===> Epoch 68 Complete: Avg. Loss: 0.0161\n",
      "===> Avg. Loss: 0.0266 \n",
      "===> Avg. Error: 0.0326 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_68.pth\n",
      "===> Epoch 69 Complete: Avg. Loss: 0.0186\n",
      "===> Avg. Loss: 0.0319 \n",
      "===> Avg. Error: 0.0387 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_69.pth\n",
      "===> Epoch 70 Complete: Avg. Loss: 0.0163\n",
      "===> Avg. Loss: 0.0336 \n",
      "===> Avg. Error: 0.0345 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_70.pth\n",
      "===> Epoch 71 Complete: Avg. Loss: 0.0115\n",
      "===> Avg. Loss: 0.0252 \n",
      "===> Avg. Error: 0.0494 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_71.pth\n",
      "===> Epoch 72 Complete: Avg. Loss: 0.0163\n",
      "===> Avg. Loss: 0.0353 \n",
      "===> Avg. Error: 0.0368 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_72.pth\n",
      "===> Epoch 73 Complete: Avg. Loss: 0.0139\n",
      "===> Avg. Loss: 0.0250 \n",
      "===> Avg. Error: 0.0357 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_73.pth\n",
      "===> Epoch 74 Complete: Avg. Loss: 0.0159\n",
      "===> Avg. Loss: 0.0254 \n",
      "===> Avg. Error: 0.0457 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_74.pth\n",
      "===> Epoch 75 Complete: Avg. Loss: 0.0169\n",
      "===> Avg. Loss: 0.0240 \n",
      "===> Avg. Error: 0.0327 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_75.pth\n",
      "===> Epoch 76 Complete: Avg. Loss: 0.0171\n",
      "===> Avg. Loss: 0.0219 \n",
      "===> Avg. Error: 0.0373 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_76.pth\n",
      "===> Epoch 77 Complete: Avg. Loss: 0.0176\n",
      "===> Avg. Loss: 0.0341 \n",
      "===> Avg. Error: 0.0307 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_77.pth\n",
      "===> Epoch 78 Complete: Avg. Loss: 0.0172\n",
      "===> Avg. Loss: 0.0264 \n",
      "===> Avg. Error: 0.0358 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_78.pth\n",
      "===> Epoch 79 Complete: Avg. Loss: 0.0166\n",
      "===> Avg. Loss: 0.0286 \n",
      "===> Avg. Error: 0.0377 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_79.pth\n",
      "===> Epoch 80 Complete: Avg. Loss: 0.0129\n",
      "===> Avg. Loss: 0.0331 \n",
      "===> Avg. Error: inf \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_80.pth\n",
      "===> Epoch 81 Complete: Avg. Loss: 0.0157\n",
      "===> Avg. Loss: 0.0307 \n",
      "===> Avg. Error: 0.0324 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_81.pth\n",
      "===> Epoch 82 Complete: Avg. Loss: 0.0120\n",
      "===> Avg. Loss: 0.0398 \n",
      "===> Avg. Error: 0.0332 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_82.pth\n",
      "===> Epoch 83 Complete: Avg. Loss: 0.0207\n",
      "===> Avg. Loss: 0.0269 \n",
      "===> Avg. Error: 0.0352 \n",
      "Checkpoint saved to ./checkpoint_databc1_larger_h5/model_epoch_83.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8840bd28fd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mL_test_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6d08ce771b4e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#         print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.item()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "L_train_loss = []\n",
    "L_test_loss = []\n",
    "L_test_error = []\n",
    "for epoch in range(1, max_epoches + 1):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss,test_error = test()\n",
    "    checkpoint(epoch)\n",
    "#     data.TestErrorPlot(model,device, testing_data_loader)\n",
    "    L_train_loss.append(train_loss)\n",
    "    L_test_loss.append(test_loss)\n",
    "    L_test_error.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./checkpoint_databc1_larger/model_epoch_27.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib \n",
    "importlib.reload(data)\n",
    "# data.TestErrorPlot(model,device, testing_data_loader)\n",
    "test_error_epoch = data.ComputeErrorVsEpoch(\"./checkpoint_largedata5_removetanh-4layerinput/\", device, testing_data_loader)\n",
    "np.savetxt('relu_4layer_test_error_epoch.out',  np.transpose(test_error_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import importlib \n",
    "importlib.reload(data)\n",
    "data.TestErrorPlot(model,device, testing_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('./checkpoint_databc1_larger/model_epoch_21.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = batch[0].to(device, torch.float), batch[1].to(device, torch.float)\n",
    "        prediction = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "prediction_L = []\n",
    "input_L = []\n",
    "target_L = []\n",
    "i=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in testing_data_loader:\n",
    "#         if ++i ==10\n",
    "        input, target = batch[0].to(device, torch.float), batch[1].to(device, torch.float)\n",
    "        input_L.append(input)\n",
    "        target_L.append(target)\n",
    "        prediction = model(input)\n",
    "        prediction_L.append(prediction)\n",
    "        i = i+1\n",
    "        if i==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    input = input_L[i].cpu().numpy()\n",
    "    target = target_L[i]\n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5):\n",
    "        im = ax[t].imshow(target[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t].axis('off')\n",
    "        ax[t].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5,10):\n",
    "        im = ax[t-5].imshow(target[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t-5].axis('off')\n",
    "        ax[t-5].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    input = input_L[i].cpu().numpy()\n",
    "    prediction = prediction_L[i]\n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5):\n",
    "        im = ax[t].imshow(prediction[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t].axis('off')\n",
    "        ax[t].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5,10):\n",
    "        im = ax[t-5].imshow(prediction[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t-5].axis('off')\n",
    "        ax[t-5].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    input = input_L[i].cpu().numpy()\n",
    "    target = target_L[i]\n",
    "    prediction = prediction_L[i]\n",
    "    for t in range(len(prediction)):\n",
    "        fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "        im = ax[0].imshow(prediction[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title(\"Prediction\")\n",
    "        im = ax[1].imshow(target[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[1].axis('off')\n",
    "        ax[1].set_title(\"Ground Truth data\")\n",
    "\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "        fig.colorbar(im, cax=cbar_ax)\n",
    "        fig.text(0.35, 0.1,\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]), fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "prediction_L = []\n",
    "input_L = []\n",
    "target_L = []\n",
    "i=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = batch[0].to(device, torch.float), batch[1].to(device, torch.float)\n",
    "        predction = model(input)\n",
    "        tmp_error = 0\n",
    "        for j in range(len(prediction)):\n",
    "            tmp_error = ComputeTestError(prediction[j], target[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    input = input_L[i].cpu().numpy()\n",
    "    target = target_L[i]\n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5):\n",
    "        im = ax[t].imshow(target[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t].axis('off')\n",
    "        ax[t].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    for t in range(5,10):\n",
    "        im = ax[t-5].imshow(target[t][0].cpu(),cmap = \"jet\")\n",
    "        ax[t-5].axis('off')\n",
    "        ax[t-5].set_title(\"D = \"+str(input[t][3][0][0])+\"  K = \"+str(input[t][2][0][0])+\"  t = \"+str(input[t][1][0][0]),size=10)\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.84, 0.27, 0.01, 0.47])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "\n",
    "plt.show()#%%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
