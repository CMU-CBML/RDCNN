{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format transformation from txt to HDF5\n",
    "\n",
    "1. Variable \"dataset_name\" needs to be modified to match the folder name of dataset \n",
    "2. Variable \"dataset_name\" needs to be modified to match the folder name of dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_files_array(filename):\n",
    "    row_data = pd.read_csv(filename,sep=' ', header=None)\n",
    "    row_data = row_data.iloc[0:,2].values    \n",
    "    matrix = row_data.astype('float').reshape(21,21)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "dataset_name = 'data_bc' # Needs to be modified to match the folder name of dataset \n",
    "fname_h5 = dataset_name + '_shuffle.hdf5'\n",
    "fname_h5_all = dataset_name + '_all.hdf5'\n",
    "path = './'+ dataset_name +'/'\n",
    "fname_lib = path + 'dataset_DKtGeo.txt'\n",
    "fld_in = path + 'input/'\n",
    "fld_out= path + 'output/'\n",
    "\n",
    "# Dataset shuffle settings\n",
    "ratio_test = 0.25 \n",
    "random_seed = 42\n",
    "shuffle_dataset = False\n",
    "\n",
    "data_lib = pd.read_csv(fname_lib, sep=\"\\t\", header=None).values\n",
    "dataset_size = len(data_lib)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(ratio_test * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, test_indices = indices[split:], indices[:split]\n",
    "    \n",
    "    train_input_shape = (len(train_indices), 4, 21, 21)\n",
    "    test_input_shape = (len(test_indices), 4, 21, 21)\n",
    "    train_output_shape = (len(train_indices), 1, 21, 21)\n",
    "    test_output_shape = (len(test_indices), 1, 21, 21)\n",
    "\n",
    "    # open a hdf5 file and create earrays\n",
    "\n",
    "    # create a new HDF5 file\n",
    "    hdf5_file = h5py.File(fname_h5, mode='w')\n",
    "\n",
    "    # # create groups in HDF5 file\n",
    "    # f.create_group('/train_input') \n",
    "    # f.create_group('/train_output')\n",
    "    # f.create_group('/test_input') \n",
    "    # f.create_group('/test_output')\n",
    "\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_input\", train_input_shape, np.float64)\n",
    "    # hdf5_file.create_dataset(\"val_input\", val_input_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"test_input\", test_input_shape, np.float64)\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_output\", train_output_shape, np.float64)\n",
    "    # hdf5_file.create_dataset(\"val_output\", val_output_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"test_output\", test_output_shape, np.float64)\n",
    "\n",
    "    count = 0\n",
    "    for index in train_indices:\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "        paraset = data_lib[index,9]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo))+ \"_\" +str(int(paraset)) + \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"train_input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"train_output\"][count, ...] = matrix_output\n",
    "        count += 1\n",
    "\n",
    "    count = 0\n",
    "    for index in test_indices:\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "        paraset = data_lib[index,9]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo))+ \"_\" +str(int(paraset)) + \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"test_input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"test_output\"][count, ...] = matrix_output    \n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    hdf5_file.close()\n",
    "else:\n",
    "    hdf5_file = h5py.File(fname_h5_all, mode='w')\n",
    "    \n",
    "    input_shape = (dataset_size, 4, 21, 21)\n",
    "    output_shape = (dataset_size, 1, 21, 21)\n",
    "\n",
    "    hdf5_file.create_dataset(\"input\", input_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"output\", output_shape, np.float64)\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for index in range(0,dataset_size):\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "        paraset = data_lib[index,9]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo))+ \"_\" +str(int(paraset)) + \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"output\"][count, ...] = matrix_output\n",
    "        count += 1\n",
    "\n",
    "    hdf5_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format transformation from txt to HDF5 (For old data without different BCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240190\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_files_array(filename):\n",
    "    row_data = pd.read_csv(filename,sep=' ', header=None)\n",
    "    row_data = row_data.iloc[0:,2].values    \n",
    "    matrix = row_data.astype('float').reshape(21,21)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "dataset_name = 'data'\n",
    "fname_h5 = dataset_name + '_shuffle.hdf5'\n",
    "fname_h5_all = dataset_name + '_all.hdf5'\n",
    "path = './'+ dataset_name +'/'\n",
    "fname_lib = path + 'dataset_DKtGeo.txt'\n",
    "fld_in = path + 'input/'\n",
    "fld_out= path + 'output/'\n",
    "\n",
    "# Shuffle dataset\n",
    "ratio_test = 0.25\n",
    "random_seed = 42\n",
    "shuffle_dataset = False\n",
    "\n",
    "data_lib = pd.read_csv(fname_lib, sep=\"\\t\", header=None).values\n",
    "dataset_size = len(data_lib)\n",
    "print(dataset_size)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(ratio_test * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, test_indices = indices[split:], indices[:split]\n",
    "    \n",
    "    train_input_shape = (len(train_indices), 4, 21, 21)\n",
    "    test_input_shape = (len(test_indices), 4, 21, 21)\n",
    "    train_output_shape = (len(train_indices), 1, 21, 21)\n",
    "    test_output_shape = (len(test_indices), 1, 21, 21)\n",
    "\n",
    "    # open a hdf5 file and create earrays\n",
    "\n",
    "    # create a new HDF5 file\n",
    "    hdf5_file = h5py.File(fname_h5, mode='w')\n",
    "\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_input\", train_input_shape, np.float64)\n",
    "    # hdf5_file.create_dataset(\"val_input\", val_input_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"test_input\", test_input_shape, np.float64)\n",
    "\n",
    "    hdf5_file.create_dataset(\"train_output\", train_output_shape, np.float64)\n",
    "    # hdf5_file.create_dataset(\"val_output\", val_output_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"test_output\", test_output_shape, np.float64)\n",
    "\n",
    "    count = 0\n",
    "    for index in train_indices:\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo))+ \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"train_input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"train_output\"][count, ...] = matrix_output\n",
    "        count += 1\n",
    "\n",
    "    count = 0\n",
    "    for index in test_indices:\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo))+ \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"test_input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"test_output\"][count, ...] = matrix_output    \n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    hdf5_file.close()\n",
    "else:\n",
    "    hdf5_file = h5py.File(fname_h5_all, mode='w')\n",
    "\n",
    "    input_shape = (dataset_size, 4, 21, 21)\n",
    "    output_shape = (dataset_size, 1, 21, 21)\n",
    "    \n",
    "    hdf5_file.create_dataset(\"input\", input_shape, np.float64)\n",
    "    hdf5_file.create_dataset(\"output\", output_shape, np.float64)\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for index in range(0,dataset_size):\n",
    "        file_num = data_lib[index,0]\n",
    "        t = data_lib[index,3]\n",
    "        k = data_lib[index,2]\n",
    "        d = data_lib[index,1]\n",
    "        geo = data_lib[index,8]\n",
    "\n",
    "        filename_output = fld_out + \"mesh_\"+str(int(file_num))+\".txt\"\n",
    "            \n",
    "        # matrix_input = torch.zeros([4,21,21], dtype = torch.float)\n",
    "        matrix_input = np.zeros((4, 21, 21), dtype=np.float64)\n",
    "        filename_input = fld_in + \"geometry_\"+str(int(geo)) + \"_input.txt\"\n",
    "        matrix_input[0] = read_files_array(filename_input )\n",
    "        matrix_input[1] = t\n",
    "        matrix_input[2] = k\n",
    "        matrix_input[3] = d\n",
    "\n",
    "        # matrix_output = torch.zeros([1,21,21], dtype = torch.float)\n",
    "        matrix_output = np.zeros((1, 21, 21), dtype=np.float64)\n",
    "        matrix_output = read_files_array(filename_output)\n",
    "\n",
    "        hdf5_file[\"input\"][count, ...] = matrix_input\n",
    "        hdf5_file[\"output\"][count, ...] = matrix_output\n",
    "        count += 1\n",
    "\n",
    "    hdf5_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
